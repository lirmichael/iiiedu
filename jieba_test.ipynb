{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fxsjy/jieba#2-添加自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from c:\\python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from c:\\python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "Loading model cost 0.406 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.406 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 獨立音樂需要大家一起來推廣，歡迎加入我們的行列！\n",
      "Output 精確模式 Full Mode：\n",
      "獨立\n",
      "音樂\n",
      "需要\n",
      "大家\n",
      "一起\n",
      "來\n",
      "推廣\n",
      "，\n",
      "歡迎\n",
      "加入\n",
      "我們\n",
      "的\n",
      "行列\n",
      "！\n",
      "Input： 独立音乐需要大家一起来推广，欢迎加入我们的行列！\n",
      "Output 精確模式 Full Mode：\n",
      "独立\n",
      "音乐\n",
      "需要\n",
      "大家\n",
      "一\n",
      "起来\n",
      "推广\n",
      "，\n",
      "欢迎\n",
      "加入\n",
      "我们\n",
      "的\n",
      "行列\n",
      "！\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "sentence = \"獨立音樂需要大家一起來推廣，歡迎加入我們的行列！\"\n",
    "print \"Input：\", sentence\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word\n",
    "\n",
    "sentence = \"独立音乐需要大家一起来推广，欢迎加入我们的行列！\"\n",
    "print \"Input：\", sentence\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\r\n",
      "我沒有真實的自我\r\n",
      "我只有消瘦的臉孔\r\n",
      "所謂軟弱\r\n",
      "所謂的順從一向是我\r\n",
      "的座右銘\r\n",
      "\r\n",
      "而我\r\n",
      "沒有那海洋的寬闊\r\n",
      "我只要熱情的撫摸\r\n",
      "所謂空洞\r\n",
      "所謂不安全感是我\r\n",
      "的墓誌銘\r\n",
      "\r\n",
      "而你\r\n",
      "是否和我一般怯懦\r\n",
      "是否和我一般矯作\r\n",
      "和我一般囉唆\r\n",
      "\r\n",
      "而你\r\n",
      "是否和我一般退縮\r\n",
      "是否和我一般肌迫\r\n",
      "一般地困惑\r\n",
      "\r\n",
      "我沒有力\r\n",
      "我沒有滿腔的熱火\r\n",
      "我只有滿肚的如果\r\n",
      "所謂勇氣\r\n",
      "所謂的認同感是我\r\n",
      "隨便說說\r\n",
      "\r\n",
      "而你\r\n",
      "是否和我一般怯懦\r\n",
      "是否和我一般矯作\r\n",
      "是否對你來說\r\n",
      "只是一場遊戲\r\n",
      "雖然沒有把握\r\n",
      "\r\n",
      "而你\r\n",
      "是否和我一般退縮\r\n",
      "是否和我一般肌迫\r\n",
      "是否對你來說\r\n",
      "只是逼不得已\r\n",
      "雖然沒有藉口\n",
      "Output 精確模式 Full Mode：\n",
      "我\n",
      "沒\n",
      "有心\n",
      "\r\n",
      "\n",
      "我\n",
      "沒\n",
      "有\n",
      "真實\n",
      "的\n",
      "自我\n",
      "\r\n",
      "\n",
      "我\n",
      "只有\n",
      "消瘦\n",
      "的\n",
      "臉孔\n",
      "\r\n",
      "\n",
      "所謂\n",
      "軟弱\n",
      "\r\n",
      "\n",
      "所謂\n",
      "的\n",
      "順\n",
      "從\n",
      "一向\n",
      "是\n",
      "我\n",
      "\r\n",
      "\n",
      "的\n",
      "座\n",
      "右銘\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "而\n",
      "我\n",
      "\r\n",
      "\n",
      "沒有\n",
      "那\n",
      "海洋\n",
      "的\n",
      "寬闊\n",
      "\r\n",
      "\n",
      "我\n",
      "只要\n",
      "熱情\n",
      "的\n",
      "撫\n",
      "摸\n",
      "\r\n",
      "\n",
      "所謂\n",
      "空洞\n",
      "\r\n",
      "\n",
      "所謂\n",
      "不安全感\n",
      "是\n",
      "我\n",
      "\r\n",
      "\n",
      "的\n",
      "墓誌\n",
      "銘\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "而\n",
      "你\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "怯懦\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "矯作\n",
      "\r\n",
      "\n",
      "和\n",
      "我\n",
      "一般\n",
      "囉\n",
      "唆\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "而\n",
      "你\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "退縮\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "肌迫\n",
      "\r\n",
      "\n",
      "一般\n",
      "地\n",
      "困惑\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "我\n",
      "沒\n",
      "有力\n",
      "\r\n",
      "\n",
      "我\n",
      "沒\n",
      "有\n",
      "滿腔\n",
      "的\n",
      "熱火\n",
      "\r\n",
      "\n",
      "我\n",
      "只有\n",
      "滿肚\n",
      "的\n",
      "如果\n",
      "\r\n",
      "\n",
      "所謂\n",
      "勇氣\n",
      "\r\n",
      "\n",
      "所謂\n",
      "的\n",
      "認\n",
      "同感\n",
      "是\n",
      "我\n",
      "\r\n",
      "\n",
      "隨便\n",
      "說\n",
      "說\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "而\n",
      "你\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "怯懦\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "矯作\n",
      "\r\n",
      "\n",
      "是否\n",
      "對\n",
      "你\n",
      "來\n",
      "說\n",
      "\r\n",
      "\n",
      "只是\n",
      "一場\n",
      "遊戲\n",
      "\r\n",
      "\n",
      "雖然\n",
      "沒\n",
      "有把握\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "而\n",
      "你\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "退縮\n",
      "\r\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "肌迫\n",
      "\r\n",
      "\n",
      "是否\n",
      "對\n",
      "你\n",
      "來\n",
      "說\n",
      "\r\n",
      "\n",
      "只是\n",
      "逼不得已\n",
      "\r\n",
      "\n",
      "雖然\n",
      "沒有\n",
      "藉口\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "content = open('D:\\III\\ETL\\Project\\lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "words = jieba.cut(content, cut_all=False)\n",
    "\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --中文歌詞斷詞，使用繁體詞庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "DEBUG:jieba:Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "Loading model cost 2.623 seconds.\n",
      "DEBUG:jieba:Loading model cost 2.623 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\n",
      "我沒有真實的自我\n",
      "我只有消瘦的臉孔\n",
      "所謂軟弱\n",
      "所謂的順從一向是我\n",
      "的座右銘\n",
      "\n",
      "而我\n",
      "沒有那海洋的寬闊\n",
      "我只要熱情的撫摸\n",
      "所謂空洞\n",
      "所謂不安全感是我\n",
      "的墓誌銘\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "和我一般囉唆\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "一般地困惑\n",
      "\n",
      "我沒有力\n",
      "我沒有滿腔的熱火\n",
      "我只有滿肚的如果\n",
      "所謂勇氣\n",
      "所謂的認同感是我\n",
      "隨便說說\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "是否對你來說\n",
      "只是一場遊戲\n",
      "雖然沒有把握\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "是否對你來說\n",
      "只是逼不得已\n",
      "雖然沒有藉口\n",
      "Output 精確模式 Full Mode：\n",
      "我\n",
      "沒有\n",
      "心\n",
      "\n",
      "\n",
      "我\n",
      "沒有\n",
      "真實\n",
      "的\n",
      "自我\n",
      "\n",
      "\n",
      "我\n",
      "只有\n",
      "消瘦\n",
      "的\n",
      "臉孔\n",
      "\n",
      "\n",
      "所謂\n",
      "軟弱\n",
      "\n",
      "\n",
      "所謂\n",
      "的\n",
      "順從\n",
      "一向\n",
      "是\n",
      "我\n",
      "\n",
      "\n",
      "的\n",
      "座右銘\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "而\n",
      "我\n",
      "\n",
      "\n",
      "沒有\n",
      "那\n",
      "海洋\n",
      "的\n",
      "寬闊\n",
      "\n",
      "\n",
      "我\n",
      "只要\n",
      "熱情\n",
      "的\n",
      "撫摸\n",
      "\n",
      "\n",
      "所謂\n",
      "空洞\n",
      "\n",
      "\n",
      "所謂\n",
      "不安全感\n",
      "是\n",
      "我\n",
      "\n",
      "\n",
      "的\n",
      "墓誌銘\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "而\n",
      "你\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "怯懦\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "矯作\n",
      "\n",
      "\n",
      "和\n",
      "我\n",
      "一般\n",
      "囉唆\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "而\n",
      "你\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "退縮\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "肌迫\n",
      "\n",
      "\n",
      "一般\n",
      "地\n",
      "困惑\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "我\n",
      "沒有\n",
      "力\n",
      "\n",
      "\n",
      "我\n",
      "沒有\n",
      "滿腔\n",
      "的\n",
      "熱火\n",
      "\n",
      "\n",
      "我\n",
      "只有\n",
      "滿肚\n",
      "的\n",
      "如果\n",
      "\n",
      "\n",
      "所謂\n",
      "勇氣\n",
      "\n",
      "\n",
      "所謂\n",
      "的\n",
      "認同感\n",
      "是\n",
      "我\n",
      "\n",
      "\n",
      "隨便說說\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "而\n",
      "你\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "怯懦\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "矯作\n",
      "\n",
      "\n",
      "是否\n",
      "對\n",
      "你\n",
      "來說\n",
      "\n",
      "\n",
      "只是\n",
      "一場\n",
      "遊戲\n",
      "\n",
      "\n",
      "雖然\n",
      "沒有\n",
      "把握\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "而\n",
      "你\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "退縮\n",
      "\n",
      "\n",
      "是否\n",
      "和\n",
      "我\n",
      "一般\n",
      "肌迫\n",
      "\n",
      "\n",
      "是否\n",
      "對\n",
      "你\n",
      "來說\n",
      "\n",
      "\n",
      "只是\n",
      "逼不得已\n",
      "\n",
      "\n",
      "雖然\n",
      "沒有\n",
      "藉口\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('D:\\III\\ETL\\Project\\lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "words = jieba.cut(content, cut_all=False)\n",
    "\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 台語歌詞斷詞，使用繁體詞庫加自定義詞庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "Loading model cost 0.665 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.665 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 親愛的媽媽\r\n",
      "請你毋通煩惱我\r\n",
      "原諒我\r\n",
      "行袂開跤\r\n",
      "我欲去對抗袂當原諒的人\r\n",
      "\r\n",
      "歹勢啦\r\n",
      "愛人啊\r\n",
      "袂當陪你去看電影\r\n",
      "原諒我\r\n",
      "行袂開跤\r\n",
      "我欲去對抗欺負咱的人\r\n",
      "\r\n",
      "天色漸漸光\r\n",
      "遮有一陣人\r\n",
      "為了守護咱的夢\r\n",
      "成做更加勇敢的人\r\n",
      "\r\n",
      "天色漸漸光\r\n",
      "已經不再驚惶\r\n",
      "現在就是彼一工\r\n",
      "換阮做守護恁的人\r\n",
      "\r\n",
      "已經袂記\r\n",
      "是第幾工\r\n",
      "請毋通煩惱我\r\n",
      "因為阮知道\r\n",
      "無行過寒冬\r\n",
      "袂有花開的一工\r\n",
      "\r\n",
      "天色漸漸光\r\n",
      "天色漸漸光\r\n",
      "已經是更加勇敢的人\r\n",
      "\r\n",
      "天色漸漸光\r\n",
      "咱就大聲來唱著歌\r\n",
      "一直到希望的光線\r\n",
      "照光島嶼每一個人\r\n",
      "\r\n",
      "天色漸漸光\r\n",
      "咱就大聲來唱著歌\r\n",
      "日頭一爬上山\r\n",
      "就會使轉去啦\r\n",
      "現在是彼一工\r\n",
      "勇敢的台灣人\n",
      "Output 精確模式 Full Mode：\n",
      "親愛\n",
      "的\n",
      "媽媽\n",
      "\r\n",
      "\n",
      "請\n",
      "你\n",
      "毋通\n",
      "煩惱\n",
      "我\n",
      "\r\n",
      "\n",
      "原諒\n",
      "我\n",
      "\r\n",
      "\n",
      "行袂開跤\n",
      "\r\n",
      "\n",
      "我\n",
      "欲\n",
      "去\n",
      "對抗\n",
      "袂當\n",
      "原諒\n",
      "的\n",
      "人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "歹勢\n",
      "啦\n",
      "\r\n",
      "\n",
      "愛人\n",
      "啊\n",
      "\r\n",
      "\n",
      "袂當\n",
      "陪你去\n",
      "看\n",
      "電影\n",
      "\r\n",
      "\n",
      "原諒\n",
      "我\n",
      "\r\n",
      "\n",
      "行袂開跤\n",
      "\r\n",
      "\n",
      "我\n",
      "欲\n",
      "去\n",
      "對抗\n",
      "欺負\n",
      "咱\n",
      "的\n",
      "人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "遮有\n",
      "一陣\n",
      "人\n",
      "\r\n",
      "\n",
      "為\n",
      "了\n",
      "守護\n",
      "咱\n",
      "的\n",
      "夢\n",
      "\r\n",
      "\n",
      "成\n",
      "做\n",
      "更加\n",
      "勇敢的人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "已經\n",
      "不再\n",
      "驚惶\n",
      "\r\n",
      "\n",
      "現在\n",
      "就是\n",
      "彼一工\n",
      "\r\n",
      "\n",
      "換阮\n",
      "做\n",
      "守護\n",
      "恁\n",
      "的\n",
      "人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "已經\n",
      "袂記\n",
      "\r\n",
      "\n",
      "是\n",
      "第幾\n",
      "工\n",
      "\r\n",
      "\n",
      "請\n",
      "毋通\n",
      "煩惱\n",
      "我\n",
      "\r\n",
      "\n",
      "因為\n",
      "阮\n",
      "知道\n",
      "\r\n",
      "\n",
      "無行過\n",
      "寒冬\n",
      "\r\n",
      "\n",
      "袂有\n",
      "花開\n",
      "的\n",
      "一工\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "已經\n",
      "是\n",
      "更加\n",
      "勇敢的人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "咱\n",
      "就\n",
      "大聲\n",
      "來\n",
      "唱著\n",
      "歌\n",
      "\r\n",
      "\n",
      "一直\n",
      "到\n",
      "希望\n",
      "的\n",
      "光線\n",
      "\r\n",
      "\n",
      "照光\n",
      "島嶼\n",
      "每\n",
      "一個\n",
      "人\n",
      "\r\n",
      "\n",
      "\r\n",
      "\n",
      "天色\n",
      "漸漸\n",
      "光\n",
      "\r\n",
      "\n",
      "咱\n",
      "就\n",
      "大聲\n",
      "來\n",
      "唱著\n",
      "歌\n",
      "\r\n",
      "\n",
      "日頭\n",
      "一爬\n",
      "上山\n",
      "\r\n",
      "\n",
      "就\n",
      "會使\n",
      "轉去\n",
      "啦\n",
      "\r\n",
      "\n",
      "現在\n",
      "是\n",
      "彼\n",
      "一工\n",
      "\r\n",
      "\n",
      "勇敢\n",
      "的\n",
      "台灣\n",
      "人\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.load_userdict(\"D:\\III\\ETL\\Project\\userdict.txt\")\n",
    "\n",
    "content = open('D:\\III\\ETL\\Project\\lyric_tw.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "words = jieba.cut(content, cut_all=False)\n",
    "\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取出斷詞詞性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\ETL\\dict.txt.big ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.ua1821025eafcbceff2396b878726e3dc.cache\n",
      "Loading model cost 0.664 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.664 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\n",
      "我沒有真實的自我\n",
      "我只有消瘦的臉孔\n",
      "所謂軟弱\n",
      "所謂的順從一向是我\n",
      "的座右銘\n",
      "\n",
      "而我\n",
      "沒有那海洋的寬闊\n",
      "我只要熱情的撫摸\n",
      "所謂空洞\n",
      "所謂不安全感是我\n",
      "的墓誌銘\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "和我一般囉唆\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "一般地困惑\n",
      "\n",
      "我沒有力\n",
      "我沒有滿腔的熱火\n",
      "我只有滿肚的如果\n",
      "所謂勇氣\n",
      "所謂的認同感是我\n",
      "隨便說說\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "是否對你來說\n",
      "只是一場遊戲\n",
      "雖然沒有把握\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "是否對你來說\n",
      "只是逼不得已\n",
      "雖然沒有藉口\n",
      "Output 精確模式 Full Mode：\n",
      "我 r\n",
      "沒有 v\n",
      "心 n\n",
      "\n",
      "x\n",
      "我 r\n",
      "沒有 v\n",
      "真實 d\n",
      "的 uj\n",
      "自我 r\n",
      "\n",
      "x\n",
      "我 r\n",
      "只有 c\n",
      "消瘦 a\n",
      "的 uj\n",
      "臉孔 n\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "軟弱 a\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "的 uj\n",
      "順從 p\n",
      "一向 d\n",
      "是 v\n",
      "我 r\n",
      "\n",
      "x\n",
      "的 uj\n",
      "座右銘 nr\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "而 c\n",
      "我 r\n",
      "\n",
      "x\n",
      "沒有 v\n",
      "那 r\n",
      "海洋 ns\n",
      "的 uj\n",
      "寬闊 a\n",
      "\n",
      "x\n",
      "我 r\n",
      "只要 c\n",
      "熱情 n\n",
      "的 uj\n",
      "撫摸 v\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "空洞 n\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "不安全感 n\n",
      "是 v\n",
      "我 r\n",
      "\n",
      "x\n",
      "的 uj\n",
      "墓誌銘 n\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "而 c\n",
      "你 r\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "怯懦 a\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "矯作 vn\n",
      "\n",
      "x\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "囉唆 v\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "而 c\n",
      "你 r\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "退縮 v\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "肌迫 n\n",
      "\n",
      "x\n",
      "一般 a\n",
      "地 uv\n",
      "困惑 a\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "我 r\n",
      "沒有 v\n",
      "力 n\n",
      "\n",
      "x\n",
      "我 r\n",
      "沒有 v\n",
      "滿腔 n\n",
      "的 uj\n",
      "熱火 n\n",
      "\n",
      "x\n",
      "我 r\n",
      "只有 c\n",
      "滿 a\n",
      "肚 ng\n",
      "的 uj\n",
      "如果 c\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "勇氣 n\n",
      "\n",
      "x\n",
      "所謂 b\n",
      "的 uj\n",
      "認同感 n\n",
      "是 v\n",
      "我 r\n",
      "\n",
      "x\n",
      "隨便說說 l\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "而 c\n",
      "你 r\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "怯懦 a\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "矯作 vn\n",
      "\n",
      "x\n",
      "是否 v\n",
      "對 p\n",
      "你 r\n",
      "來說 u\n",
      "\n",
      "x\n",
      "只是 c\n",
      "一場 m\n",
      "遊戲 n\n",
      "\n",
      "x\n",
      "雖然 c\n",
      "沒有 v\n",
      "把握 v\n",
      "\n",
      "x\n",
      "\n",
      "x\n",
      "而 c\n",
      "你 r\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "退縮 v\n",
      "\n",
      "x\n",
      "是否 v\n",
      "和 c\n",
      "我 r\n",
      "一般 a\n",
      "肌迫 n\n",
      "\n",
      "x\n",
      "是否 v\n",
      "對 p\n",
      "你 r\n",
      "來說 u\n",
      "\n",
      "x\n",
      "只是 c\n",
      "逼不得已 i\n",
      "\n",
      "x\n",
      "雖然 c\n",
      "沒有 v\n",
      "藉口 nr\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('D:\\III\\ETL\\Project\\lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "words = pseg.cut(content)\n",
    "\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for word in words:\n",
    "    print word.word, word.flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取出斷詞位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "DEBUG:jieba:Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "Loading model cost 2.648 seconds.\n",
      "DEBUG:jieba:Loading model cost 2.648 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\n",
      "我沒有真實的自我\n",
      "我只有消瘦的臉孔\n",
      "所謂軟弱\n",
      "所謂的順從一向是我\n",
      "的座右銘\n",
      "\n",
      "而我\n",
      "沒有那海洋的寬闊\n",
      "我只要熱情的撫摸\n",
      "所謂空洞\n",
      "所謂不安全感是我\n",
      "的墓誌銘\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "和我一般囉唆\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "一般地困惑\n",
      "\n",
      "我沒有力\n",
      "我沒有滿腔的熱火\n",
      "我只有滿肚的如果\n",
      "所謂勇氣\n",
      "所謂的認同感是我\n",
      "隨便說說\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "是否對你來說\n",
      "只是一場遊戲\n",
      "雖然沒有把握\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "是否對你來說\n",
      "只是逼不得已\n",
      "雖然沒有藉口\n",
      "Output 精確模式 Full Mode：\n",
      "word 我\t\t start: 0 \t\t end:1\n",
      "word 沒有\t\t start: 1 \t\t end:3\n",
      "word 心\t\t start: 3 \t\t end:4\n",
      "word \n",
      "\t\t start: 4 \t\t end:6\n",
      "word 我\t\t start: 6 \t\t end:7\n",
      "word 沒有\t\t start: 7 \t\t end:9\n",
      "word 真實\t\t start: 9 \t\t end:11\n",
      "word 的\t\t start: 11 \t\t end:12\n",
      "word 自我\t\t start: 12 \t\t end:14\n",
      "word \n",
      "\t\t start: 14 \t\t end:16\n",
      "word 我\t\t start: 16 \t\t end:17\n",
      "word 只有\t\t start: 17 \t\t end:19\n",
      "word 消瘦\t\t start: 19 \t\t end:21\n",
      "word 的\t\t start: 21 \t\t end:22\n",
      "word 臉孔\t\t start: 22 \t\t end:24\n",
      "word \n",
      "\t\t start: 24 \t\t end:26\n",
      "word 所謂\t\t start: 26 \t\t end:28\n",
      "word 軟弱\t\t start: 28 \t\t end:30\n",
      "word \n",
      "\t\t start: 30 \t\t end:32\n",
      "word 所謂\t\t start: 32 \t\t end:34\n",
      "word 的\t\t start: 34 \t\t end:35\n",
      "word 順從\t\t start: 35 \t\t end:37\n",
      "word 一向\t\t start: 37 \t\t end:39\n",
      "word 是\t\t start: 39 \t\t end:40\n",
      "word 我\t\t start: 40 \t\t end:41\n",
      "word \n",
      "\t\t start: 41 \t\t end:43\n",
      "word 的\t\t start: 43 \t\t end:44\n",
      "word 座右銘\t\t start: 44 \t\t end:47\n",
      "word \n",
      "\t\t start: 47 \t\t end:49\n",
      "word \n",
      "\t\t start: 49 \t\t end:51\n",
      "word 而\t\t start: 51 \t\t end:52\n",
      "word 我\t\t start: 52 \t\t end:53\n",
      "word \n",
      "\t\t start: 53 \t\t end:55\n",
      "word 沒有\t\t start: 55 \t\t end:57\n",
      "word 那\t\t start: 57 \t\t end:58\n",
      "word 海洋\t\t start: 58 \t\t end:60\n",
      "word 的\t\t start: 60 \t\t end:61\n",
      "word 寬闊\t\t start: 61 \t\t end:63\n",
      "word \n",
      "\t\t start: 63 \t\t end:65\n",
      "word 我\t\t start: 65 \t\t end:66\n",
      "word 只要\t\t start: 66 \t\t end:68\n",
      "word 熱情\t\t start: 68 \t\t end:70\n",
      "word 的\t\t start: 70 \t\t end:71\n",
      "word 撫摸\t\t start: 71 \t\t end:73\n",
      "word \n",
      "\t\t start: 73 \t\t end:75\n",
      "word 所謂\t\t start: 75 \t\t end:77\n",
      "word 空洞\t\t start: 77 \t\t end:79\n",
      "word \n",
      "\t\t start: 79 \t\t end:81\n",
      "word 所謂\t\t start: 81 \t\t end:83\n",
      "word 不安全感\t\t start: 83 \t\t end:87\n",
      "word 是\t\t start: 87 \t\t end:88\n",
      "word 我\t\t start: 88 \t\t end:89\n",
      "word \n",
      "\t\t start: 89 \t\t end:91\n",
      "word 的\t\t start: 91 \t\t end:92\n",
      "word 墓誌銘\t\t start: 92 \t\t end:95\n",
      "word \n",
      "\t\t start: 95 \t\t end:97\n",
      "word \n",
      "\t\t start: 97 \t\t end:99\n",
      "word 而\t\t start: 99 \t\t end:100\n",
      "word 你\t\t start: 100 \t\t end:101\n",
      "word \n",
      "\t\t start: 101 \t\t end:103\n",
      "word 是否\t\t start: 103 \t\t end:105\n",
      "word 和\t\t start: 105 \t\t end:106\n",
      "word 我\t\t start: 106 \t\t end:107\n",
      "word 一般\t\t start: 107 \t\t end:109\n",
      "word 怯懦\t\t start: 109 \t\t end:111\n",
      "word \n",
      "\t\t start: 111 \t\t end:113\n",
      "word 是否\t\t start: 113 \t\t end:115\n",
      "word 和\t\t start: 115 \t\t end:116\n",
      "word 我\t\t start: 116 \t\t end:117\n",
      "word 一般\t\t start: 117 \t\t end:119\n",
      "word 矯作\t\t start: 119 \t\t end:121\n",
      "word \n",
      "\t\t start: 121 \t\t end:123\n",
      "word 和\t\t start: 123 \t\t end:124\n",
      "word 我\t\t start: 124 \t\t end:125\n",
      "word 一般\t\t start: 125 \t\t end:127\n",
      "word 囉唆\t\t start: 127 \t\t end:129\n",
      "word \n",
      "\t\t start: 129 \t\t end:131\n",
      "word \n",
      "\t\t start: 131 \t\t end:133\n",
      "word 而\t\t start: 133 \t\t end:134\n",
      "word 你\t\t start: 134 \t\t end:135\n",
      "word \n",
      "\t\t start: 135 \t\t end:137\n",
      "word 是否\t\t start: 137 \t\t end:139\n",
      "word 和\t\t start: 139 \t\t end:140\n",
      "word 我\t\t start: 140 \t\t end:141\n",
      "word 一般\t\t start: 141 \t\t end:143\n",
      "word 退縮\t\t start: 143 \t\t end:145\n",
      "word \n",
      "\t\t start: 145 \t\t end:147\n",
      "word 是否\t\t start: 147 \t\t end:149\n",
      "word 和\t\t start: 149 \t\t end:150\n",
      "word 我\t\t start: 150 \t\t end:151\n",
      "word 一般\t\t start: 151 \t\t end:153\n",
      "word 肌迫\t\t start: 153 \t\t end:155\n",
      "word \n",
      "\t\t start: 155 \t\t end:157\n",
      "word 一般\t\t start: 157 \t\t end:159\n",
      "word 地\t\t start: 159 \t\t end:160\n",
      "word 困惑\t\t start: 160 \t\t end:162\n",
      "word \n",
      "\t\t start: 162 \t\t end:164\n",
      "word \n",
      "\t\t start: 164 \t\t end:166\n",
      "word 我\t\t start: 166 \t\t end:167\n",
      "word 沒有\t\t start: 167 \t\t end:169\n",
      "word 力\t\t start: 169 \t\t end:170\n",
      "word \n",
      "\t\t start: 170 \t\t end:172\n",
      "word 我\t\t start: 172 \t\t end:173\n",
      "word 沒有\t\t start: 173 \t\t end:175\n",
      "word 滿腔\t\t start: 175 \t\t end:177\n",
      "word 的\t\t start: 177 \t\t end:178\n",
      "word 熱火\t\t start: 178 \t\t end:180\n",
      "word \n",
      "\t\t start: 180 \t\t end:182\n",
      "word 我\t\t start: 182 \t\t end:183\n",
      "word 只有\t\t start: 183 \t\t end:185\n",
      "word 滿肚\t\t start: 185 \t\t end:187\n",
      "word 的\t\t start: 187 \t\t end:188\n",
      "word 如果\t\t start: 188 \t\t end:190\n",
      "word \n",
      "\t\t start: 190 \t\t end:192\n",
      "word 所謂\t\t start: 192 \t\t end:194\n",
      "word 勇氣\t\t start: 194 \t\t end:196\n",
      "word \n",
      "\t\t start: 196 \t\t end:198\n",
      "word 所謂\t\t start: 198 \t\t end:200\n",
      "word 的\t\t start: 200 \t\t end:201\n",
      "word 認同感\t\t start: 201 \t\t end:204\n",
      "word 是\t\t start: 204 \t\t end:205\n",
      "word 我\t\t start: 205 \t\t end:206\n",
      "word \n",
      "\t\t start: 206 \t\t end:208\n",
      "word 隨便說說\t\t start: 208 \t\t end:212\n",
      "word \n",
      "\t\t start: 212 \t\t end:214\n",
      "word \n",
      "\t\t start: 214 \t\t end:216\n",
      "word 而\t\t start: 216 \t\t end:217\n",
      "word 你\t\t start: 217 \t\t end:218\n",
      "word \n",
      "\t\t start: 218 \t\t end:220\n",
      "word 是否\t\t start: 220 \t\t end:222\n",
      "word 和\t\t start: 222 \t\t end:223\n",
      "word 我\t\t start: 223 \t\t end:224\n",
      "word 一般\t\t start: 224 \t\t end:226\n",
      "word 怯懦\t\t start: 226 \t\t end:228\n",
      "word \n",
      "\t\t start: 228 \t\t end:230\n",
      "word 是否\t\t start: 230 \t\t end:232\n",
      "word 和\t\t start: 232 \t\t end:233\n",
      "word 我\t\t start: 233 \t\t end:234\n",
      "word 一般\t\t start: 234 \t\t end:236\n",
      "word 矯作\t\t start: 236 \t\t end:238\n",
      "word \n",
      "\t\t start: 238 \t\t end:240\n",
      "word 是否\t\t start: 240 \t\t end:242\n",
      "word 對\t\t start: 242 \t\t end:243\n",
      "word 你\t\t start: 243 \t\t end:244\n",
      "word 來說\t\t start: 244 \t\t end:246\n",
      "word \n",
      "\t\t start: 246 \t\t end:248\n",
      "word 只是\t\t start: 248 \t\t end:250\n",
      "word 一場\t\t start: 250 \t\t end:252\n",
      "word 遊戲\t\t start: 252 \t\t end:254\n",
      "word \n",
      "\t\t start: 254 \t\t end:256\n",
      "word 雖然\t\t start: 256 \t\t end:258\n",
      "word 沒有\t\t start: 258 \t\t end:260\n",
      "word 把握\t\t start: 260 \t\t end:262\n",
      "word \n",
      "\t\t start: 262 \t\t end:264\n",
      "word \n",
      "\t\t start: 264 \t\t end:266\n",
      "word 而\t\t start: 266 \t\t end:267\n",
      "word 你\t\t start: 267 \t\t end:268\n",
      "word \n",
      "\t\t start: 268 \t\t end:270\n",
      "word 是否\t\t start: 270 \t\t end:272\n",
      "word 和\t\t start: 272 \t\t end:273\n",
      "word 我\t\t start: 273 \t\t end:274\n",
      "word 一般\t\t start: 274 \t\t end:276\n",
      "word 退縮\t\t start: 276 \t\t end:278\n",
      "word \n",
      "\t\t start: 278 \t\t end:280\n",
      "word 是否\t\t start: 280 \t\t end:282\n",
      "word 和\t\t start: 282 \t\t end:283\n",
      "word 我\t\t start: 283 \t\t end:284\n",
      "word 一般\t\t start: 284 \t\t end:286\n",
      "word 肌迫\t\t start: 286 \t\t end:288\n",
      "word \n",
      "\t\t start: 288 \t\t end:290\n",
      "word 是否\t\t start: 290 \t\t end:292\n",
      "word 對\t\t start: 292 \t\t end:293\n",
      "word 你\t\t start: 293 \t\t end:294\n",
      "word 來說\t\t start: 294 \t\t end:296\n",
      "word \n",
      "\t\t start: 296 \t\t end:298\n",
      "word 只是\t\t start: 298 \t\t end:300\n",
      "word 逼不得已\t\t start: 300 \t\t end:304\n",
      "word \n",
      "\t\t start: 304 \t\t end:306\n",
      "word 雖然\t\t start: 306 \t\t end:308\n",
      "word 沒有\t\t start: 308 \t\t end:310\n",
      "word 藉口\t\t start: 310 \t\t end:312\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "words = jieba.tokenize(unicode(content, 'utf-8'))\n",
    "\n",
    "print \"Output 精確模式 Full Mode：\"\n",
    "for tk in words:\n",
    "    print \"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取出文章中的關鍵詞\n",
    "#jieba 使用了 tf-idf 方法來實作萃取出文章中關鍵詞的功能：\n",
    "程式中的 jieba.analyse.extract_tags(content, 10)，就是告訴 jieba 我們要從這個文章中取出前 10 個 tf-idf 值最大的關鍵詞。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "Loading model cost 0.745 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.745 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\n",
      "我沒有真實的自我\n",
      "我只有消瘦的臉孔\n",
      "所謂軟弱\n",
      "所謂的順從一向是我\n",
      "的座右銘\n",
      "\n",
      "而我\n",
      "沒有那海洋的寬闊\n",
      "我只要熱情的撫摸\n",
      "所謂空洞\n",
      "所謂不安全感是我\n",
      "的墓誌銘\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "和我一般囉唆\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "一般地困惑\n",
      "\n",
      "我沒有力\n",
      "我沒有滿腔的熱火\n",
      "我只有滿肚的如果\n",
      "所謂勇氣\n",
      "所謂的認同感是我\n",
      "隨便說說\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "是否對你來說\n",
      "只是一場遊戲\n",
      "雖然沒有把握\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "是否對你來說\n",
      "只是逼不得已\n",
      "雖然沒有藉口\n",
      "Output：\n",
      "沒有,所謂,是否,一般,退縮,雖然,肌迫,矯作,來說,怯懦\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, 10)\n",
    "\n",
    "print \"Output：\"\n",
    "print \",\".join(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\dict.txt.big ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u85b74997e35969fbce3735381a00d21e.cache\n",
      "Loading model cost 0.714 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.714 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 我沒有心\n",
      "我沒有真實的自我\n",
      "我只有消瘦的臉孔\n",
      "所謂軟弱\n",
      "所謂的順從一向是我\n",
      "的座右銘\n",
      "\n",
      "而我\n",
      "沒有那海洋的寬闊\n",
      "我只要熱情的撫摸\n",
      "所謂空洞\n",
      "所謂不安全感是我\n",
      "的墓誌銘\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "和我一般囉唆\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "一般地困惑\n",
      "\n",
      "我沒有力\n",
      "我沒有滿腔的熱火\n",
      "我只有滿肚的如果\n",
      "所謂勇氣\n",
      "所謂的認同感是我\n",
      "隨便說說\n",
      "\n",
      "而你\n",
      "是否和我一般怯懦\n",
      "是否和我一般矯作\n",
      "是否對你來說\n",
      "只是一場遊戲\n",
      "雖然沒有把握\n",
      "\n",
      "而你\n",
      "是否和我一般退縮\n",
      "是否和我一般肌迫\n",
      "是否對你來說\n",
      "只是逼不得已\n",
      "雖然沒有藉口\n",
      "Output：\n",
      "沒有,所謂,是否,一般,退縮,雖然,肌迫,矯作,來說,怯懦,逼不得已,墓誌銘,寬闊,順從,熱情,遊戲,認同感,囉唆,滿肚,勇氣\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyric.txt', 'rb').read()\n",
    "\n",
    "print \"Input：\", content\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content)\n",
    "\n",
    "print \"Output：\"\n",
    "print \",\".join(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " jieba 有提供一個 idf 的語料庫，但在實務上每個人所使用的語料庫可能會不太一樣，有時我們會想要使用自己的idf 語料庫，stop words 的語料庫也可能會想換成自己的，比如目前的結果中，最重要的「座右銘」並沒有出現在關鍵詞裡，我就會想要將「座右銘」加到 idf 語料庫，並讓 idf 值高一點，而「沒有」這個關鍵詞對我來說是沒有用的，我就會想把它加到 stop words 語料庫，這樣「沒有」就不會出現在關鍵詞裡。\n",
    "\n",
    "可惜目前 pip 安裝的 jieba 版本並不能切換 idf 及 stop words 語料庫，所以我才會修改了一下 jieba，讓它可以支援 idf 及 stop words 語料庫的切換，目前在 github 上的版本已經可以支援 idf 及 stop words 切換的功能了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#特点\n",
    "支持三种分词模式：\n",
    "\n",
    "精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\n",
    "支持繁体分词\n",
    "\n",
    "支持自定义词典\n",
    "MIT 授权协议\n",
    "\n",
    "#算法\n",
    "基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)\n",
    "采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合\n",
    "对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法\n",
    "\n",
    "#主要功能\n",
    "1. 分词\n",
    "jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型\n",
    "jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "jieba.lcut 以及 jieba.lcut_for_search 直接返回 list\n",
    "jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "2. Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "3. 新词识别:\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "4. 搜索引擎模式:\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n",
      "<generator object cut_for_search at 0x0F4048A0>\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"1. Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"2. Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\"3. 新词识别:\")\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\"4. 搜索引擎模式:\")\n",
    "print(\", \".join(seg_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2. 添加自定义词典\n",
    "\n",
    "载入词典\n",
    "\n",
    "开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率\n",
    "用法： jieba.load_userdict(file_name) # file_name 为自定义词典的路径\n",
    "词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。\n",
    "词频省略时使用自动计算的能保证分出该词的词频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-eeec58fbe137>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-eeec58fbe137>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    print(w.word, \"/\", w.flag, \", \", end=\" \")\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#encoding=utf-8\n",
    "#from __future__ import print_function, unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"D:\\III\\ETL\\Project\\userdict.txt\")\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))\n",
    "\n",
    "print(\"=\"*40)\n",
    "\n",
    "result = pseg.cut(test_sent)\n",
    "\n",
    "for w in result:\n",
    "    print(w.word, \"/\", w.flag, \", \", end=\" \")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "\n",
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新办/主任/也/是/云计算/方面/的/专家/;/ /什么/是/八一双鹿/，/例如/我/输入/一个/带/“/韩玉赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/，/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n",
      "========================================\n",
      "easy_install/ /is/ /great\n",
      "python/ /的/正则表达式/是/好用/的\n",
      "========================================\n",
      "今天天气/不错\n",
      "今天天气 Before: None, After: 0\n",
      "今天天气/不错\n",
      "----------------------------------------\n",
      "如果/放到/post/中/将/出错/。\n",
      "中将 Before: None, After: 494\n",
      "如果/放到/post/中/将/出错/。\n",
      "----------------------------------------\n",
      "我们/中/出/了/一个/叛徒\n",
      "中出 Before: None, After: 3\n",
      "我们/中/出/了/一个/叛徒\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "#from __future__ import print_function, unicode_literals\n",
    "#import sys\n",
    "#sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"D:\\III\\Project\\patent\\iiiedu\\userdict_1.txt\")\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿，例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类，「台中」正確應該不會被切開。\"\n",
    "    \"mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    "    \n",
    ")\n",
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))\n",
    "\n",
    "print(\"=\"*40)\n",
    "\n",
    "result = pseg.cut(test_sent)\n",
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "\n",
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "调整词典\n",
    "\n",
    "使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "\n",
    "注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。\n",
    "\n",
    ">>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "如果/放到/post/中将/出错/。\n",
    ">>> jieba.suggest_freq(('中', '将'), True)\n",
    "494\n",
    ">>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "如果/放到/post/中/将/出错/。\n",
    ">>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "「/台/中/」/正确/应该/不会/被/切开\n",
    ">>> jieba.suggest_freq('台中', True)\n",
    "69\n",
    ">>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "「/台中/」/正确/应该/不会/被/切开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"通过用户自定义词典来增强歧义纠错能力\" --- https://github.com/fxsjy/jieba/issues/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n",
      "如果/放到/post/中/将/出错/。\n",
      "「/台中/」/正确/应该/不会/被/切开\n",
      "「/台中/」/正确/应该/不会/被/切开\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "#from __future__ import print_function, unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"D:\\III\\Project\\patent\\iiiedu\\userdict_1.txt\")\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "\n",
    "\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中将/出错/。\n",
    "jieba.suggest_freq(('中', '将'), True)\n",
    "#494\n",
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))\n",
    "#如果/放到/post/中/将/出错/。\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台/中/」/正确/应该/不会/被/切开\n",
    "jieba.suggest_freq('台中', True)\n",
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))\n",
    "#「/台中/」/正确/应该/不会/被/切开\n",
    "print('/'.join(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 关键词提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于 TF-IDF 算法的关键词抽取\n",
    "\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "sentence 为待提取的文本\n",
    "topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件\n",
    "代码示例 （关键词提取）\n",
    "\n",
    "https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py\n",
    "\n",
    "关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径\n",
    "自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py\n",
    "关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径\n",
    "自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py\n",
    "关键词一并返回关键词权重值示例\n",
    "\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "基于 TF-IDF 算法的关键词抽取\n",
    "\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "sentence 为待提取的文本\n",
    "topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件\n",
    "代码示例 （关键词提取）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:    python extract_tags.py [file name] -k [top k]\n",
      "\n",
      "__main__.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "USAGE = \"usage:    python extract_tags.py [file name] -k [top k]\"\n",
    "\n",
    "parser = OptionParser(USAGE)\n",
    "parser.add_option(\"-k\", dest=\"topK\")\n",
    "opt, args = parser.parse_args()\n",
    "\n",
    "\n",
    "if len(args) < 1:\n",
    "    print(USAGE)\n",
    "    sys.exit(1)\n",
    "\n",
    "file_name = args[0]\n",
    "\n",
    "if opt.topK is None:\n",
    "    topK = 10\n",
    "else:\n",
    "    topK = int(opt.topK)\n",
    "\n",
    "content = open(file_name, 'rb').read()\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, topK=topK)\n",
    "\n",
    "print(\",\".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径\n",
    "自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "USAGE = \"usage:    python extract_tags_idfpath.py [file name] -k [top k]\"\n",
    "\n",
    "parser = OptionParser(USAGE)\n",
    "parser.add_option(\"-k\", dest=\"topK\")\n",
    "opt, args = parser.parse_args()\n",
    "\n",
    "\n",
    "if len(args) < 1:\n",
    "    print(USAGE)\n",
    "    sys.exit(1)\n",
    "\n",
    "file_name = args[0]\n",
    "\n",
    "if opt.topK is None:\n",
    "    topK = 10\n",
    "else:\n",
    "    topK = int(opt.topK)\n",
    "\n",
    "content = open(file_name, 'rb').read()\n",
    "\n",
    "jieba.analyse.set_idf_path(\"../extra_dict/idf.txt.big\");\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, topK=topK)\n",
    "\n",
    "print(\",\".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径\n",
    "自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "USAGE = \"usage:    python extract_tags_stop_words.py [file name] -k [top k]\"\n",
    "\n",
    "parser = OptionParser(USAGE)\n",
    "parser.add_option(\"-k\", dest=\"topK\")\n",
    "opt, args = parser.parse_args()\n",
    "\n",
    "\n",
    "if len(args) < 1:\n",
    "    print(USAGE)\n",
    "    sys.exit(1)\n",
    "\n",
    "file_name = args[0]\n",
    "\n",
    "if opt.topK is None:\n",
    "    topK = 10\n",
    "else:\n",
    "    topK = int(opt.topK)\n",
    "\n",
    "content = open(file_name, 'rb').read()\n",
    "\n",
    "jieba.analyse.set_stop_words(\"../extra_dict/stop_words.txt\")\n",
    "jieba.analyse.set_idf_path(\"../extra_dict/idf.txt.big\");\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, topK=topK)\n",
    "\n",
    "print(\",\".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4. 词性标注\n",
    "\n",
    "jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。\n",
    "标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from c:\\python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "DEBUG:jieba:Building prefix dict from c:\\python27\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "DEBUG:jieba:Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.cache\n",
      "Loading model cost 1.511 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.511 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5. 并行分词\n",
    "\n",
    "原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升\n",
    "基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows\n",
    "\n",
    "用法：\n",
    "\n",
    "jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数\n",
    "jieba.disable_parallel() # 关闭并行分词模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_file.py\n",
    "\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"D:\\III\\Project\\patent\\iiiedu\\fxsjy\\jieba-master\\test\\parallel\")\n",
    "import jieba\n",
    "\n",
    "jieba.enable_parallel()\n",
    "\n",
    "url = sys.argv[1]\n",
    "content = open(url,\"rb\").read()\n",
    "t1 = time.time()\n",
    "words = \"/ \".join(jieba.cut(content))\n",
    "\n",
    "t2 = time.time()\n",
    "tm_cost = t2-t1\n",
    "\n",
    "log_f = open(\"1.log\",\"wb\")\n",
    "log_f.write(words.encode('utf-8'))\n",
    "\n",
    "print('speed %s bytes/second' % (len(content)/tm_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "6. Tokenize：返回词语在原文的起止位置\n",
    "\n",
    "注意，输入参数只接受 unicode\n",
    "默认模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "搜索模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "7. ChineseAnalyzer for Whoosh 搜索引擎\n",
    "\n",
    "引用： from jieba.analyse import ChineseAnalyzer\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named whoosh.index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-beb78b025c7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwhoosh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_in\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopen_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwhoosh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwhoosh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQueryParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named whoosh.index"
     ]
    }
   ],
   "source": [
    "#test_whoosh.py\n",
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "from whoosh.index import create_in,open_dir\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "from jieba.analyse import ChineseAnalyzer\n",
    "\n",
    "analyzer = ChineseAnalyzer()\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT(stored=True, analyzer=analyzer))\n",
    "if not os.path.exists(\"tmp\"):\n",
    "    os.mkdir(\"tmp\")\n",
    "\n",
    "ix = create_in(\"tmp\", schema) # for create new index\n",
    "#ix = open_dir(\"tmp\") # for read only\n",
    "writer = ix.writer()\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document1\",\n",
    "    path=\"/a\",\n",
    "    content=\"This is the first document we’ve added!\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document2\",\n",
    "    path=\"/b\",\n",
    "    content=\"The second one 你 中文测试中文 is even more interesting! 吃水果\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document3\",\n",
    "    path=\"/c\",\n",
    "    content=\"买水果然后来世博园。\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document4\",\n",
    "    path=\"/c\",\n",
    "    content=\"工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\"\n",
    ")\n",
    "\n",
    "writer.add_document(\n",
    "    title=\"document4\",\n",
    "    path=\"/c\",\n",
    "    content=\"咱俩交换一下吧。\"\n",
    ")\n",
    "\n",
    "writer.commit()\n",
    "searcher = ix.searcher()\n",
    "parser = QueryParser(\"content\", schema=ix.schema)\n",
    "\n",
    "for keyword in (\"水果世博园\",\"你\",\"first\",\"中文\",\"交换机\",\"交换\"):\n",
    "    print(\"result of \",keyword)\n",
    "    q = parser.parse(keyword)\n",
    "    results = searcher.search(q)\n",
    "    for hit in results:\n",
    "        print(hit.highlights(\"content\"))\n",
    "    print(\"=\"*10)\n",
    "\n",
    "for t in analyzer(\"我的好朋友是李明;我爱北京天安门;IBM和Microsoft; I have a dream. this is intetesting and interested me a lot\"):\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "延迟加载机制\n",
    "\n",
    "jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。\n",
    "\n",
    "import jieba\n",
    "jieba.initialize()  # 手动初始化（可选）\n",
    "在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:\n",
    "\n",
    "jieba.set_dictionary('data/dict.txt.big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\foobar.txt ...\n",
      "DEBUG:jieba:Building prefix dict from D:\\III\\Project\\patent\\iiiedu\\foobar.txt ...\n",
      "Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u5312969037b012e1eae3d14443611eef.cache\n",
      "DEBUG:jieba:Dumping model to file cache c:\\users\\michael\\appdata\\local\\temp\\jieba.u5312969037b012e1eae3d14443611eef.cache\n",
      "Loading model cost 0.113 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.113 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是  一个  伸手不见五指  的  黑夜  。  我  叫  孙悟空  ，  我  爱  北京  ，  我  爱  Python  和  C++  。\n",
      "我  不  喜欢  日本  和服  。\n",
      "雷猴  回归  人间  。\n",
      "工信处  女干事  每月  经过  下属  科室  都  要  亲口  交代  24  口  交换机  等  技术性  器件  的  安装  工作\n",
      "我  需要  廉租房\n",
      "永和  服装  饰品  有限公司\n",
      "我  爱  北京  天安门\n",
      "abc\n",
      "隐  马尔可夫\n",
      "雷猴  是  个  好  网站\n",
      "================================\n",
      "这是  一个  伸手  不见  五指  的  黑夜  。  我  叫  孙悟空  ，  我  爱北京  ，  我  爱  Python  和  C  ++  。\n",
      "我  不  喜欢  日本  和  服  。\n",
      "雷猴  回归人间  。\n",
      "工信  处女  干事  每  月  经过  下  属  科室  都  要  亲口  交代  24  口交换机  等  技术性  器件  的  安装  工作\n",
      "我  需要  廉租房\n",
      "永和服  装饰品  有  限公司\n",
      "我  爱北京  天安门\n",
      "abc\n",
      "隐马尔  可夫\n",
      "雷猴  是  个  好  网站\n"
     ]
    }
   ],
   "source": [
    "#test_change_dictpath.py\n",
    "#encoding=utf-8\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "\n",
    "def cuttest(test_sent):\n",
    "    result = jieba.cut(test_sent)\n",
    "    print(\"  \".join(result))\n",
    "\n",
    "def testcase():\n",
    "    cuttest(\"这是一个伸手不见五指的黑夜。我叫孙悟空，我爱北京，我爱Python和C++。\")\n",
    "    cuttest(\"我不喜欢日本和服。\")\n",
    "    cuttest(\"雷猴回归人间。\")\n",
    "    cuttest(\"工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\")\n",
    "    cuttest(\"我需要廉租房\")\n",
    "    cuttest(\"永和服装饰品有限公司\")\n",
    "    cuttest(\"我爱北京天安门\")\n",
    "    cuttest(\"abc\")\n",
    "    cuttest(\"隐马尔可夫\")\n",
    "    cuttest(\"雷猴是个好网站\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    testcase()\n",
    "    jieba.set_dictionary(\"foobar.txt\")\n",
    "    print(\"================================\")\n",
    "    testcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
